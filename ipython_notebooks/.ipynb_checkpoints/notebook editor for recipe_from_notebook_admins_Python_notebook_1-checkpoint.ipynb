{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "associatedRecipe": "recipe_from_notebook_admins_Python_notebook_1",
    "creator": "admin",
    "createdOn": 1627624612864,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {}
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import dataiku\n",
        "from dataiku import spark as dkuspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.stat import Correlation\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.types import StructType, StructField, StringType\n",
        "\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "sc \u003d SparkContext.getOrCreate()\n",
        "sqlContext \u003d SQLContext(sc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Read recipe inputs\n",
        "fitness \u003d dataiku.Dataset(\"FITNESS\")\n",
        "fitness_df \u003d dkuspark.get_dataframe(sqlContext, fitness)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "fitness_df \u003d fitness_df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "column_names \u003d fitness_df.columns\n",
        "corr_method \u003d dataiku.get_custom_variables()[\"corr_method\"]\n",
        "vector_col \u003d \"corr_features\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "corr_method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# convert to vector column first\n",
        "assembler \u003d VectorAssembler(inputCols\u003dfitness_df.columns, outputCol\u003dvector_col)\n",
        "df_vector \u003d assembler.transform(fitness_df).select(vector_col)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "matrix \u003d Correlation.corr(df_vector, vector_col, method\u003dcorr_method)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "type(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "matrix.show(truncate\u003dFalse)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "cor_np \u003d matrix.collect()[0][\"pearson({})\".format(vector_col)].values\n",
        "cor_np"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "type(cor_np)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "dim \u003d int(math.sqrt(len(cor_np)))\n",
        "cor_mat \u003d cor_np.reshape((dim,dim))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "cor_mat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Approach 1. - Failed\n",
        "df_spark \u003d sqlContext.createDataFrame(pd.DataFrame(cor_mat))\n",
        "df_spark.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Approach 2. - Failed\n",
        "corr_data\u003d pd.DataFrame(cor_mat, index\u003d column_names,columns \u003d column_names).reset_index()\n",
        "corr_pyspark_df \u003d spark.createDataFrame(corr_data)\n",
        "corr_pyspark_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Write recipe outputs\n",
        "corr_pyspark \u003d dataiku.Dataset(\"corr_pyspark\")\n",
        "dkuspark.write_with_schema(corr_pyspark, df_spark)"
      ]
    }
  ]
}