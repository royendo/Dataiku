{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "2.7.16",
      "name": "python",
      "pygments_lexer": "ipython2",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    },
    "creator": "admin",
    "createdOn": 1636162628402,
    "hide_input": false,
    "modifiedBy": "admin",
    "customFields": {},
    "tags": []
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": []
    },
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport pprint as pp\n\nclient \u003d dataiku.api_client()\nprojects \u003d client.list_projects()\nfor project_key in client.list_project_keys():\n    project \u003d client.get_project(project_key)\n    recipes \u003d project.list_recipes()\n    for recipe in recipes:\n        \n        if \"params\" in recipe:\n            if \"engineType\" in recipe[\"params\"]:\n                if recipe[\"params\"][\"engineType\"] \u003d\u003d \"SPARK\":\n                    changeRecipe \u003d project.get_recipe(recipe.name)\n                    settings \u003d changeRecipe.get_settings()\n                    pp.pprint(settings.raw_params[\"engineParams\"])\n                    #settings.raw_params[\"engineParams\"][\"spark\"][\"sparkConfig\"][\"inheritConf\"] \u003d \"default\"\n                    #settings.save()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{u\u0027hadoopConfigKeys\u0027: [],\n u\u0027hive\u0027: {u\u0027addDkuUdf\u0027: False,\n           u\u0027executionEngine\u0027: u\u0027HIVESERVER2\u0027,\n           u\u0027hiveconf\u0027: [],\n           u\u0027inheritConf\u0027: u\u0027default\u0027,\n           u\u0027skipPrerunValidate\u0027: False},\n u\u0027impala\u0027: {u\u0027forceStreamMode\u0027: True},\n u\u0027maxThreads\u0027: 8,\n u\u0027spark\u0027: {u\u0027executionEngine\u0027: u\u0027SPARK_SUBMIT\u0027,\n            u\u0027pipelineAllowMerge\u0027: True,\n            u\u0027pipelineAllowStart\u0027: True,\n            u\u0027readParams\u0027: {u\u0027autoModeRepartitionInto\u0027: 10,\n                            u\u0027map\u0027: {u\u0027DKU_TUTORIAL_BASICS_101_WINE_QUALITY__2__COPY\u0027: {u\u0027repartition\u0027: 10}},\n                            u\u0027mode\u0027: u\u0027AUTO\u0027},\n            u\u0027skipPrerunValidate\u0027: False,\n            u\u0027sparkConfig\u0027: {u\u0027conf\u0027: [], u\u0027inheritConf\u0027: u\u0027default\u0027},\n            u\u0027useGlobalMetastore\u0027: False,\n            u\u0027useNativeProcessors\u0027: True},\n u\u0027sqlPipelineParams\u0027: {u\u0027pipelineAllowMerge\u0027: True,\n                        u\u0027pipelineAllowStart\u0027: True}}\n{u\u0027hive\u0027: {u\u0027addDkuUdf\u0027: False,\n           u\u0027executionEngine\u0027: u\u0027HIVECLI_LOCAL\u0027,\n           u\u0027hiveconf\u0027: [],\n           u\u0027inheritConf\u0027: u\u0027default\u0027,\n           u\u0027skipPrerunValidate\u0027: False},\n u\u0027impala\u0027: {u\u0027forceStreamMode\u0027: True},\n u\u0027lowerCaseSchemaIfEngineRequiresIt\u0027: False,\n u\u0027maxThreads\u0027: 4,\n u\u0027sparkSQL\u0027: {u\u0027executionEngine\u0027: u\u0027SPARK_SUBMIT\u0027,\n               u\u0027overwriteOutputSchema\u0027: False,\n               u\u0027pipelineAllowMerge\u0027: True,\n               u\u0027pipelineAllowStart\u0027: True,\n               u\u0027readParams\u0027: {u\u0027autoModeRepartitionInto\u0027: 10,\n                               u\u0027map\u0027: {},\n                               u\u0027mode\u0027: u\u0027AUTO\u0027},\n               u\u0027skipPrerunValidate\u0027: False,\n               u\u0027sparkConfig\u0027: {u\u0027conf\u0027: [], u\u0027inheritConf\u0027: u\u0027default\u0027},\n               u\u0027useGlobalMetastore\u0027: False},\n u\u0027sqlPipelineParams\u0027: {u\u0027pipelineAllowMerge\u0027: True,\n                        u\u0027pipelineAllowStart\u0027: True},\n u\u0027tdchParams\u0027: {u\u0027numberOfExecutors\u0027: 2, u\u0027splitMode\u0027: u\u0027DEFAULT\u0027}}\n{u\u0027hadoopConfigKeys\u0027: [],\n u\u0027hive\u0027: {u\u0027addDkuUdf\u0027: False,\n           u\u0027executionEngine\u0027: u\u0027HIVECLI_LOCAL\u0027,\n           u\u0027hiveconf\u0027: [],\n           u\u0027inheritConf\u0027: u\u0027default\u0027,\n           u\u0027skipPrerunValidate\u0027: False},\n u\u0027impala\u0027: {u\u0027forceStreamMode\u0027: True},\n u\u0027maxThreads\u0027: 8,\n u\u0027spark\u0027: {u\u0027executionEngine\u0027: u\u0027SPARK_SUBMIT\u0027,\n            u\u0027pipelineAllowMerge\u0027: True,\n            u\u0027pipelineAllowStart\u0027: True,\n            u\u0027readParams\u0027: {u\u0027autoModeRepartitionInto\u0027: 10,\n                            u\u0027map\u0027: {u\u0027CIDP_HCP_alignment_sync\u0027: {u\u0027repartition\u0027: 10}},\n                            u\u0027mode\u0027: u\u0027AUTO\u0027},\n            u\u0027skipPrerunValidate\u0027: False,\n            u\u0027sparkConfig\u0027: {u\u0027conf\u0027: [], u\u0027inheritConf\u0027: u\u0027default\u0027},\n            u\u0027useGlobalMetastore\u0027: False,\n            u\u0027useNativeProcessors\u0027: True},\n u\u0027sqlPipelineParams\u0027: {u\u0027pipelineAllowMerge\u0027: True,\n                        u\u0027pipelineAllowStart\u0027: True}}\n{u\u0027hive\u0027: {u\u0027addDkuUdf\u0027: False,\n           u\u0027executionEngine\u0027: u\u0027HIVECLI_LOCAL\u0027,\n           u\u0027hiveconf\u0027: [],\n           u\u0027inheritConf\u0027: u\u0027default\u0027,\n           u\u0027skipPrerunValidate\u0027: False},\n u\u0027impala\u0027: {u\u0027forceStreamMode\u0027: True},\n u\u0027lowerCaseSchemaIfEngineRequiresIt\u0027: False,\n u\u0027maxThreads\u0027: 4,\n u\u0027sparkSQL\u0027: {u\u0027executionEngine\u0027: u\u0027SPARK_SUBMIT\u0027,\n               u\u0027overwriteOutputSchema\u0027: False,\n               u\u0027pipelineAllowMerge\u0027: True,\n               u\u0027pipelineAllowStart\u0027: True,\n               u\u0027readParams\u0027: {u\u0027autoModeRepartitionInto\u0027: 10,\n                               u\u0027map\u0027: {},\n                               u\u0027mode\u0027: u\u0027AUTO\u0027},\n               u\u0027skipPrerunValidate\u0027: False,\n               u\u0027sparkConfig\u0027: {u\u0027conf\u0027: [], u\u0027inheritConf\u0027: u\u0027default\u0027},\n               u\u0027useGlobalMetastore\u0027: False},\n u\u0027sqlPipelineParams\u0027: {u\u0027pipelineAllowMerge\u0027: True,\n                        u\u0027pipelineAllowStart\u0027: True},\n u\u0027tdchParams\u0027: {u\u0027numberOfExecutors\u0027: 2, u\u0027splitMode\u0027: u\u0027DEFAULT\u0027}}\n{u\u0027hive\u0027: {u\u0027addDkuUdf\u0027: False,\n           u\u0027executionEngine\u0027: u\u0027HIVECLI_LOCAL\u0027,\n           u\u0027hiveconf\u0027: [],\n           u\u0027inheritConf\u0027: u\u0027default\u0027,\n           u\u0027skipPrerunValidate\u0027: False},\n u\u0027impala\u0027: {u\u0027forceStreamMode\u0027: True},\n u\u0027lowerCaseSchemaIfEngineRequiresIt\u0027: False,\n u\u0027maxThreads\u0027: 4,\n u\u0027sparkSQL\u0027: {u\u0027executionEngine\u0027: u\u0027SPARK_SUBMIT\u0027,\n               u\u0027overwriteOutputSchema\u0027: False,\n               u\u0027pipelineAllowMerge\u0027: True,\n               u\u0027pipelineAllowStart\u0027: True,\n               u\u0027readParams\u0027: {u\u0027autoModeRepartitionInto\u0027: 10,\n                               u\u0027map\u0027: {},\n                               u\u0027mode\u0027: u\u0027AUTO\u0027},\n               u\u0027skipPrerunValidate\u0027: False,\n               u\u0027sparkConfig\u0027: {u\u0027conf\u0027: [], u\u0027inheritConf\u0027: u\u0027default\u0027},\n               u\u0027useGlobalMetastore\u0027: False},\n u\u0027sqlPipelineParams\u0027: {u\u0027pipelineAllowMerge\u0027: True,\n                        u\u0027pipelineAllowStart\u0027: True},\n u\u0027tdchParams\u0027: {u\u0027numberOfExecutors\u0027: 2, u\u0027splitMode\u0027: u\u0027DEFAULT\u0027}}\n{u\u0027hive\u0027: {u\u0027addDkuUdf\u0027: False,\n           u\u0027executionEngine\u0027: u\u0027HIVECLI_LOCAL\u0027,\n           u\u0027hiveconf\u0027: [],\n           u\u0027inheritConf\u0027: u\u0027default\u0027,\n           u\u0027skipPrerunValidate\u0027: False},\n u\u0027impala\u0027: {u\u0027forceStreamMode\u0027: True},\n u\u0027lowerCaseSchemaIfEngineRequiresIt\u0027: False,\n u\u0027maxThreads\u0027: 4,\n u\u0027sparkSQL\u0027: {u\u0027executionEngine\u0027: u\u0027SPARK_SUBMIT\u0027,\n               u\u0027overwriteOutputSchema\u0027: False,\n               u\u0027pipelineAllowMerge\u0027: True,\n               u\u0027pipelineAllowStart\u0027: True,\n               u\u0027readParams\u0027: {u\u0027autoModeRepartitionInto\u0027: 10,\n                               u\u0027map\u0027: {},\n                               u\u0027mode\u0027: u\u0027AUTO\u0027},\n               u\u0027skipPrerunValidate\u0027: False,\n               u\u0027sparkConfig\u0027: {u\u0027conf\u0027: [], u\u0027inheritConf\u0027: u\u0027default\u0027},\n               u\u0027useGlobalMetastore\u0027: False},\n u\u0027sqlPipelineParams\u0027: {u\u0027pipelineAllowMerge\u0027: True,\n                        u\u0027pipelineAllowStart\u0027: True},\n u\u0027tdchParams\u0027: {u\u0027numberOfExecutors\u0027: 2, u\u0027splitMode\u0027: u\u0027DEFAULT\u0027}}\n{u\u0027hadoopConfigKeys\u0027: [],\n u\u0027hive\u0027: {u\u0027addDkuUdf\u0027: False,\n           u\u0027executionEngine\u0027: u\u0027HIVECLI_LOCAL\u0027,\n           u\u0027hiveconf\u0027: [],\n           u\u0027inheritConf\u0027: u\u0027default\u0027,\n           u\u0027skipPrerunValidate\u0027: False},\n u\u0027impala\u0027: {u\u0027forceStreamMode\u0027: True},\n u\u0027maxThreads\u0027: 8,\n u\u0027spark\u0027: {u\u0027executionEngine\u0027: u\u0027SPARK_SUBMIT\u0027,\n            u\u0027pipelineAllowMerge\u0027: True,\n            u\u0027pipelineAllowStart\u0027: True,\n            u\u0027readParams\u0027: {u\u0027autoModeRepartitionInto\u0027: 10,\n                            u\u0027map\u0027: {u\u0027GLBHOSIMSMIDASRWDETL.ig_weekly_monthly_ntb_flag_P17\u0027: {u\u0027repartition\u0027: 10},\n                                     u\u0027ig_weekly_monthly_ntb_flag_P17_joined\u0027: {u\u0027repartition\u0027: 10},\n                                     u\u0027ig_weekly_monthly_ntb_flag_P17_stacked\u0027: {u\u0027repartition\u0027: 10},\n                                     u\u0027sql_ig_p17_p5_stacked\u0027: {u\u0027repartition\u0027: 10}},\n                            u\u0027mode\u0027: u\u0027AUTO\u0027},\n            u\u0027skipPrerunValidate\u0027: False,\n            u\u0027sparkConfig\u0027: {u\u0027conf\u0027: [], u\u0027inheritConf\u0027: u\u0027yarn-large\u0027},\n            u\u0027useGlobalMetastore\u0027: False,\n            u\u0027useNativeProcessors\u0027: True},\n u\u0027sqlPipelineParams\u0027: {u\u0027pipelineAllowMerge\u0027: True,\n                        u\u0027pipelineAllowStart\u0027: True}}\n{u\u0027hive\u0027: {u\u0027addDkuUdf\u0027: False,\n           u\u0027executionEngine\u0027: u\u0027HIVECLI_LOCAL\u0027,\n           u\u0027hiveconf\u0027: [],\n           u\u0027inheritConf\u0027: u\u0027default\u0027,\n           u\u0027skipPrerunValidate\u0027: False},\n u\u0027impala\u0027: {u\u0027forceStreamMode\u0027: True},\n u\u0027lowerCaseSchemaIfEngineRequiresIt\u0027: False,\n u\u0027maxThreads\u0027: 4,\n u\u0027sparkSQL\u0027: {u\u0027executionEngine\u0027: u\u0027SPARK_SUBMIT\u0027,\n               u\u0027overwriteOutputSchema\u0027: False,\n               u\u0027pipelineAllowMerge\u0027: True,\n               u\u0027pipelineAllowStart\u0027: True,\n               u\u0027readParams\u0027: {u\u0027autoModeRepartitionInto\u0027: 10,\n                               u\u0027map\u0027: {},\n                               u\u0027mode\u0027: u\u0027AUTO\u0027},\n               u\u0027skipPrerunValidate\u0027: False,\n               u\u0027sparkConfig\u0027: {u\u0027conf\u0027: [], u\u0027inheritConf\u0027: u\u0027default\u0027},\n               u\u0027useGlobalMetastore\u0027: False},\n u\u0027sqlPipelineParams\u0027: {u\u0027pipelineAllowMerge\u0027: True,\n                        u\u0027pipelineAllowStart\u0027: True},\n u\u0027tdchParams\u0027: {u\u0027numberOfExecutors\u0027: 2, u\u0027splitMode\u0027: u\u0027DEFAULT\u0027}}\n{u\u0027hadoopConfigKeys\u0027: [],\n u\u0027hive\u0027: {u\u0027addDkuUdf\u0027: False,\n           u\u0027executionEngine\u0027: u\u0027HIVECLI_LOCAL\u0027,\n           u\u0027hiveconf\u0027: [],\n           u\u0027inheritConf\u0027: u\u0027default\u0027,\n           u\u0027skipPrerunValidate\u0027: False},\n u\u0027impala\u0027: {u\u0027forceStreamMode\u0027: True},\n u\u0027maxThreads\u0027: 8,\n u\u0027spark\u0027: {u\u0027executionEngine\u0027: u\u0027SPARK_SUBMIT\u0027,\n            u\u0027pipelineAllowMerge\u0027: True,\n            u\u0027pipelineAllowStart\u0027: True,\n            u\u0027readParams\u0027: {u\u0027autoModeRepartitionInto\u0027: 10,\n                            u\u0027map\u0027: {u\u0027ig_rx_px_spec_unmapped_recurring_P7_sync_joined\u0027: {u\u0027repartition\u0027: 10}},\n                            u\u0027mode\u0027: u\u0027AUTO\u0027},\n            u\u0027skipPrerunValidate\u0027: False,\n            u\u0027sparkConfig\u0027: {u\u0027conf\u0027: [], u\u0027inheritConf\u0027: u\u0027default\u0027},\n            u\u0027useGlobalMetastore\u0027: False,\n            u\u0027useNativeProcessors\u0027: True},\n u\u0027sqlPipelineParams\u0027: {u\u0027pipelineAllowMerge\u0027: True,\n                        u\u0027pipelineAllowStart\u0027: True}}\n"
        }
      ]
    },
    {
      "execution_count": 20,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport pprint as pp\n\nclient \u003d dataiku.api_client()\nprojects \u003d client.list_projects()\nfor project_key in client.list_project_keys():\n    project \u003d client.get_project(project_key)\n    recipes \u003d project.list_recipes()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{u\u0027engineParams\u0027: {u\u0027hadoopConfigKeys\u0027: [],\n                   u\u0027hive\u0027: {u\u0027addDkuUdf\u0027: False,\n                             u\u0027executionEngine\u0027: u\u0027HIVESERVER2\u0027,\n                             u\u0027hiveconf\u0027: [],\n                             u\u0027inheritConf\u0027: u\u0027default\u0027,\n                             u\u0027skipPrerunValidate\u0027: False},\n                   u\u0027impala\u0027: {u\u0027forceStreamMode\u0027: True},\n                   u\u0027maxThreads\u0027: 8,\n                   u\u0027spark\u0027: {u\u0027executionEngine\u0027: u\u0027SPARK_SUBMIT\u0027,\n                              u\u0027pipelineAllowMerge\u0027: True,\n                              u\u0027pipelineAllowStart\u0027: True,\n                              u\u0027readParams\u0027: {u\u0027autoModeRepartitionInto\u0027: 10,\n                                              u\u0027map\u0027: {u\u0027DKU_TUTORIAL_BASICS_101_WINE_QUALITY__2__COPY\u0027: {u\u0027repartition\u0027: 10}},\n                                              u\u0027mode\u0027: u\u0027AUTO\u0027},\n                              u\u0027skipPrerunValidate\u0027: False,\n                              u\u0027sparkConfig\u0027: {u\u0027conf\u0027: [],\n                                               u\u0027inheritConf\u0027: u\u0027default\u0027},\n                              u\u0027useGlobalMetastore\u0027: False,\n                              u\u0027useNativeProcessors\u0027: True},\n                   u\u0027sqlPipelineParams\u0027: {u\u0027pipelineAllowMerge\u0027: True,\n                                          u\u0027pipelineAllowStart\u0027: True}},\n u\u0027engineType\u0027: u\u0027SPARK\u0027}\n"
        }
      ]
    },
    {
      "execution_count": 17,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nx \u003d dataiku.get_custom_variables(typed \u003d True)[\"test\"]\nprint(x[\u0027a\u0027])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1\n"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}